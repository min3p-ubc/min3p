!*****Revision Informations Automatically Generated by VisualSVN*****!
!---------------------------------------------------------------------
!> $ID:$
!> $Revision: 94 $
!> $Author: dsu $
!> $Date: 2013-06-11 14:43:47 -0700 (Tue, 11 Jun 2013) $
!> $URL: https://biot.eos.ubc.ca/svn/min3p_thcm/branches/dsu_mp/src/solver/solver.cfg $
!---------------------------------------------------------------------
!********************************************************************!

!> **********************************************************
!>              Block:  Golbal solver setting
!> **********************************************************
!> This command indicates that the input parameters in the MIN3P input
!> file have the priority over the input parameters in the parallel
!> solver configuration file.
!> By default, the parameters in this file will overwrite the same
!> parameters in the MIN3P input file.
!> For example, if there are solver convergence parameters in both 
!> files, you can use the following command if you want to use MIN3P
!> input parameters first.
!> Requirement: Optional
!> 
! GLOBAL: USE MIN3P INPUT PARAMETERS FIRST

!> Select solver
!> i_solver_type = 0 use ws209 solver (default)
!>                 1 use pardiso solver
!>                 2 use PETSc solver
!> Requirement: Optional
!> Note: this setting is for both flow solver and reactive transport solver
!SOLVER TYPE
!1

!> i_solver_type_flow = 0 use ws209 solver (default)
!>                      1 use pardiso solver
!>                      2 use PETSc solver
!> Requirement: Optional if use ws209 solver
!>              Required if use pardiso solver
SOLVER TYPE FLOW
0

!>
!> i_solver_type_react = 0 use ws209 solver (default)
!>                       1 use pardiso solver
!>                       2 use PETSc solver
!> Requirement: Optional if use ws209 solver
!>              Required if use pardiso solver
SOLVER TYPE REACTIVE TRANSPORT
0

!>
!> Use number of threads from MPI calling.
!> If this command is enabled, the number of threads
!> in OpenMP calling will be replaced by the number 
!> of processors in mpi calling.
!GLOBAL: USE NUMBER OF THREADS FROM MPI

!>
!> Set the number of threads for global use
!> Default value: 1
!> Requirement: Optional
GLOBAL: NUMBER OF THREADS
8
!>
!> Loops like vector initialization will be parallelized if 
!> the loops number is larger than this threshold.
!> Default value: 1000
GLOBAL: NUMBER OF LOOPS THRESHOLD
8 

!> **********************************************************
!>              Block:  Matrix assembly setting
!> **********************************************************

!>
!> Set the matrix assembly type for flow problem
!> i_matrix_assembly_type_flow = 0 use sequential mode (default)
!>                               1 use Openmp parallel mode
!>                               2 use MPI parallel mode (not in use) 
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
MATRIX ASSEMBLY: TYPE IN FLOW
1

!>
!> Set the number of threads in matrix assembly for flow problem.
!> If not specified, use 'GLOBAL: NUMBER OF THREADS' instead.
!> Default value: 1
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
MATRIX ASSEMBLY: NUMBER OF THREADS IN FLOW
8

!> Set the schedule type in matrix assembly for flow problem.
!> If not specified, use the dynamic schedule method.
!> Current the schedule method is compiler configured.
!> i_schedule_type_flow = 0 use static schedule method (not in use)
!>                        1 use dynamic schedule method (not in use)
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
MATRIX ASSEMBLY: SCHEDULE TYPE IN FLOW
0

!> Set the chunk size factor for matrix assembly for flow problem.
!> This value should be from 0 to (number of volumes)/(number of processors).
!> If larger than (number of volumes)/(number of processors), the chunk size
!> will be set to 1.
!> If the value is not specified or 0, use the system default size. 
!> i_chunksize_factor_flow = 0 use system default size
!>                           1-n
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
MATRIX ASSEMBLY: CHUNK SIZE FACTOR IN FLOW
100


!>
!> Set the matrix assembly type for reactive transport problem
!> i_matrix_assembly_type_react = 0 use sequential mode (default)
!>                                1 use Openmp parallel mode
!>                                2 use MPI parallel mode (not in use) 
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
MATRIX ASSEMBLY: TYPE IN REACTIVE TRANSPORT 
1

!>
!> Set the number of threads in matrix assembly for reactive 
!> transport problem.
!> If not specified, use 'GLOBAL: NUMBER OF THREADS' instead.
!> Default value: 1
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
MATRIX ASSEMBLY: NUMBER OF THREADS IN REACTIVE TRANSPORT
8

!> Set the schedule type in matrix assembly for reactive 
!> transport problem.
!> If not specified, use the dynamic schedule method.
!> Current the schedule method is compiler configured.
!> i_schedule_type_flow = 0 use static schedule method (not in use)
!>                         1 use dynamic schedule method (not in use)
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
MATRIX ASSEMBLY: SCHEDULE TYPE IN REACTIVE TRANSPORT
0

!> Set the chunk size factor for matrix assembly for reactive 
!> transport problem.
!> This value should be from 0 to (number of volumes)/(number of processors).
!> If the value is not specified or 0, use the system default size. 
!> If larger than (number of volumes)/(number of processors), the chunk size
!> will be set to 1. 
!> i_chunksize_factor_react = 0 use system default size
!>                            1-n
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
MATRIX ASSEMBLY: CHUNK SIZE FACTOR IN REACTIVE TRANSPORT
100

!> **********************************************************
!>              Block:  Pardiso solver setting
!> **********************************************************

!> Set this parameter if you want to check the result of matrix
!> solver with ws209. Only valid if  i_solver_type = 0
!> Requirement: Optional if you need to compare the result of
!>              matrix solver.
!PARDISO: SOLVER TEST WITH WS209

!> Set the number of threads for pardiso solver.
!> If the solver type is not pardiso, ignore it.
!> If the number of threads is less than 1, use dynamic
!> number of threads determined by pardiso. 
!> Default value: 1
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
PARDISO: NUMBER OF THREADS
8

!> Maximum number of iterative refinement steps that the 
!> solver will perform. The solver will perform not more 
!> than the absolute value of this parameter for iterative
!> refinement and will stop the process if a satisfactory
!> level of accuracy of the solution in terms of backward
!> error has been achieved.
!> If this parameter is negative, the accumulation of the
!> residuum is using extended precision real types.
!> Default value: 9
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
PARDISO: MAX ITERATIVE REFINEMENT STEPS IN FLOW
9

PARDISO: MAX ITERATIVE REFINEMENT STEPS IN REACTIVE TRANSPORT
9

!> This parameter instructs PARDISO how to handle small
!> pivots or zero pivots for unsymmetric matrices. 
!> It indicates the iterative refinement contraction
!> rate. The default value is 13, which means eps = 10^(-13)
!> is used in handling small pivots.
!> Default value: 13
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
PARDISO: PIVOTING PERTURBATION IN FLOW
13

PARDISO: PIVOTING PERTURBATION IN REACTIVE TRANSPORT
13

!> This parameter controls preconditioned CGS [Sonn89] for nonsymmetric matrices. iparm(4) has the form iparm(4)= 10*L+K.
!> K=0 The factorization is always computed as required by phase.
!> K=1 CGS iteration replaces the computation of LU. The preconditioner is LU that was computed at a previous step 
!> (the first step or last step with a failure) in a sequence of solutions needed for identical sparsity patterns.
!> iparm(4)    Description 
!> 31    LU-preconditioned CGS iteration with a stopping criterion of 1.0E-3 for nonsymmetric matrices 
!> 61    LU-preconditioned CGS iteration with a stopping criterion of 1.0E-6 for nonsymmetric matrices 
!> Default value: 0
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
PARDISO: CGS CRITERION IN FLOW
0

PARDISO: CGS CRITERION IN REACTIVE TRANSPORT
0

!> This parameter control when symbolic factorization should take.
!> In pardiso solver, when the previous reordering is not quite good 
!> to get correct results, reorder the matrix (symbolic factorization) again.
!> For nonsymmetric case, it's better to call reorder step for each matrix,
!> but this can waste a lot of time.
!> When preconditioned CGS is used, this value will be compared to the number of completed iterations,
!> otherwise, this value will be compared to the number of iterative refinement steps performed.
!> When the iteration number is larger than the provided, do symblic factorization again.
!> Default value: 9
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
PARDISO: MAXIMUM SOLVER ITERATION IN FLOW
5
PARDISO: MAXIMUM SOLVER ITERATION IN REACTIVE TRANSPORT   
5

!> This parameter control when symbolic factorization should take.
!> In pardiso solver, when the previous reordering is not quite good 
!> to get correct results, reorder the matrix (symbolic factorization) again.
!> For nonsymmetric case, it's better to call reorder step for each matrix,
!> but this can waste a lot of time. 
!> When the maximum residual is larger than the provided, do symblic factorization again.
!> Default value: 1.0E-5
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
PARDISO: MAXIMUM RESIDUAL IN FLOW
1.0E-5
PARDISO: MAXIMUM RESIDUAL IN REACTIVE TRANSPORT
1.0E-5

!> This parameter control when symbolic factorization should take.
!> In pardiso solver, when the previous reordering is not quite good 
!> to get correct results, reorder the matrix (symbolic factorization) again.
!> For nonsymmetric case, it's better to call reorder step for each matrix,
!> but this can waste a lot of time. 
!> 0 symbolic factorization at first run
!> 1 symbolic factorization every step
!> Default value: 0
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
PARDISO: SYMBOLIC FACTORIZATION TYPE IN FLOW
0

PARDISO: SYMBOLIC FACTORIZATION TYPE IN REACTIVE TRANSPORT
0

!> **********************************************************
!>              Block:  PETSc solver setting
!> **********************************************************
!> Set this parameter if you want to check the result of matrix
!> solver with ws209. Only valid if  i_solver_type = 0
!> Requirement: Optional if you need to compare the result of
!>              matrix solver.
! PETSC: SOLVER TEST WITH WS209
!> Set PETSc Krylov method for flow problem
!> The following method are supported in PETSc
!> KSPRICHARDSON "richardson"
!> KSPCHEBYSHEV  "chebyshev"
!> KSPCG         "cg"
!> KSPGROPPCG    "groppcg"
!> KSPPIPECG     "pipecg"
!> KSPCGNE       "cgne"
!> KSPNASH       "nash"
!> KSPSTCG       "stcg"
!> KSPGLTR       "gltr"
!> KSPGMRES      "gmres"
!> KSPFGMRES     "fgmres"
!> KSPLGMRES     "lgmres"
!> KSPDGMRES     "dgmres"
!> KSPPGMRES     "pgmres"
!> KSPTCQMR      "tcqmr"
!> KSPBCGS       "bcgs"
!> KSPIBCGS      "ibcgs"
!> KSPFBCGS      "fbcgs"
!> KSPFBCGSR     "fbcgsr"
!> KSPBCGSL      "bcgsl"
!> KSPCGS        "cgs"
!> KSPTFQMR      "tfqmr"
!> KSPCR         "cr"
!> KSPPIPECR     "pipecr"
!> KSPLSQR       "lsqr"
!> KSPPREONLY    "preonly"
!> KSPQCG        "qcg"
!> KSPBICG       "bicg"
!> KSPMINRES     "minres"
!> KSPSYMMLQ     "symmlq"
!> KSPLCD        "lcd"
!> KSPPYTHON     "python"
!> KSPGCR        "gcr"
!> KSPSPECEST    "specest"
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
!> Input example:
!>               PETSC: KSP TYPE IN FLOW
!>               gmres
!> The default value is gmres
PETSC: KSP TYPE IN FLOW
gmres
!> Set the relative convergence tolerance for flow problem
!> The default value is 1.0E-5
PETSC: RELATIVE CONVERGENCE TOLERANCE IN FLOW
1.0E-5 
!> Set the absolute convergence tolerance for flow problem
!> The default value is 1.0E-10
PETSC: ABSOLUTE CONVERGENCE TOLERANCE IN FLOW
1.0E-12 
!> Set the divergence tolerance for flow problem
!> The default value is 1.0E5
PETSC: DIVERGENCE TOLERANCE IN FLOW
1.0E5
!> Set the maximum number of iterations for flow problem
!> The default value is 1000
PETSC: MAXIMUM NUMBER OF ITERATIONS IN FLOW
1000
!> Set PETSc Krylov method for reactive transport problem
!> The following method are supported in PETSc
!> KSPRICHARDSON "richardson"
!> KSPCHEBYSHEV  "chebyshev"
!> KSPCG         "cg"
!> KSPGROPPCG    "groppcg"
!> KSPPIPECG     "pipecg"
!> KSPCGNE       "cgne"
!> KSPNASH       "nash"
!> KSPSTCG       "stcg"
!> KSPGLTR       "gltr"
!> KSPGMRES      "gmres"
!> KSPFGMRES     "fgmres"
!> KSPLGMRES     "lgmres"
!> KSPDGMRES     "dgmres"
!> KSPPGMRES     "pgmres"
!> KSPTCQMR      "tcqmr"
!> KSPBCGS       "bcgs"
!> KSPIBCGS      "ibcgs"
!> KSPFBCGS      "fbcgs"
!> KSPFBCGSR     "fbcgsr"
!> KSPBCGSL      "bcgsl"
!> KSPCGS        "cgs"
!> KSPTFQMR      "tfqmr"
!> KSPCR         "cr"
!> KSPPIPECR     "pipecr"
!> KSPLSQR       "lsqr"
!> KSPPREONLY    "preonly"
!> KSPQCG        "qcg"
!> KSPBICG       "bicg"
!> KSPMINRES     "minres"
!> KSPSYMMLQ     "symmlq"
!> KSPLCD        "lcd"
!> KSPPYTHON     "python"
!> KSPGCR        "gcr"
!> KSPSPECEST    "specest"
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
!> Input example:
!>               PETSC: KSP TYPE IN REACTIVE TRANSPORT
!>               gmres
!> The default value is gmres
PETSC: KSP TYPE IN REACTIVE TRANSPORT
gmres
!> Set the relative convergence tolerance for reactive transport problem
!> The default value is 1.0E-5
PETSC: RELATIVE CONVERGENCE TOLERANCE IN REACTIVE TRANSPORT
1.0E-6 
!> Set the absolute convergence tolerance for reactive transport problem
!> The default value is 1.0E-20
PETSC: ABSOLUTE CONVERGENCE TOLERANCE IN REACTIVE TRANSPORT
1.0E-12 
!> Set the divergence tolerance for reactive transport problem
!> The default value is 1.0E5
PETSC: DIVERGENCE TOLERANCE IN REACTIVE TRANSPORT
1.0E5
!> Set the maximum number of iterations for reactive transport problem
!> The default value is 1000
PETSC: MAXIMUM NUMBER OF ITERATIONS IN REACTIVE TRANSPORT
1000
!> **********************************************************
!>              Block:  ws209 solver setting
!> **********************************************************

!> Set the number of threads for ws209 solver.
!> Only works when the solver type is ws209.
!> Default value: 1
!> Requirement: Optional if use sequential mode
!>              Required if use parallel mode
!> Note: WS209 (WatSolv) solver is not fully parallelized.
WS209: NUMBER OF THREADS
8

!> **********************************************************
!>              Block:  Output setting
!> **********************************************************

!> Set if output detail runtime statistics analysis.
!> Comment out if you do not want to export it.
!> Requirement: Required if runtime profile is needed.
OUTPUT RUNTIME STATISTICS ANALYSIS

!> Set if output the matrix data for all the linear equations.
!> Comment out if you do not want to export it.
!> Requirement: Optional, only for test.
! OUTPUT SPARSE MATRIX DATA SET AND RHS

!> Estimate condition number of matrix before solving euations.
!> Enable this will increase the running time. 
!> Comment out if you do not want to export it.
!> Requirement: Required if condition number is needed.
! OUTPUT CONDITION NUMBER

!> **********************************************************
!>              Block:  OpenMP Parallel Controls 
!> **********************************************************
!> Format: Command for specified subroutine
!>         Threshold for loop amount
!> If the threshold is smaller than the loop amount, OpenMP 
!> parallelization is enabled for this subroutine, otherwise,
!> if the threshold is larger than the loop amount, OpenMP
!> parallelization is disabled for this subroutine.
!> **********************************************************
mbalrt: number of threads 1
1
mbalrt: number of threads 2
1
mbalrt: number of threads 3
1
mbalrt: number of threads 4
1
mbalrt: number of threads 5
1
mbalrt: number of threads 6
1
mbalrt: number of threads 7
1
mbalrt: number of threads 8
1
mbalrt: number of threads 9
1
mbalrt: number of threads 10
1
mbalrt: number of threads 11
1
msysrt: number of threads 1
1
msysrt: number of threads 2
1
msysrt: number of threads 3
1
msysrt: number of threads 4
1
msysrt: number of threads 5
1
msysrt: number of threads 6
1
mbal_mcd: number of threads 1
1
mbal_mcd: number of threads 2
1
mbal_mcd: number of threads 3
1
infcrtdd: number of threads 1
1
infcrtdd: number of threads 2
1
infcrtdd: number of threads 3
1
infcrt_a: number of threads 1
1
infcrt_a: number of threads 2
1
infcrt_a: number of threads 3
1
infcrt_g: number of threads 1
1
infcrt_g: number of threads 2
1
infcrt_mcd: number of threads 1
1
infcrt_mcd: number of threads 2
1
diffcoff_mcd: number of threads 1
1
i2upfind: number of threads 1
1
i2upfind_heat: number of threads 1
1
ddtds: number of threads 1
1
ddtds_energybal: number of threads 1
1
ddtds_energybal: number of threads 2
1
comp_bc_ice: number of threads 1
1
comp_bc_ice: number of threads 2
1
timeloop: number of threads 1
1
infheat_c: number of threads 1
1
infheat_d: number of threads 1
1
infevap: number of threads 1
1
updatedd: number of threads 1
1
updatedd: number of threads 2
1
updatedd_ener: number of threads 1
1
updatedd_ener: number of threads 2
1
updatedd_ener: number of threads 3
1
ddvsflow: number of threads 1
1
seepfdd: number of threads 1
1
tstepvs: number of threads 1
1
updatevs: number of threads 1
1
updatevs: number of threads 2
1
seepface: number of threads 1
1
soilparm: number of threads 1
1
msysdd: number of threads 1
1
msysdd: number of threads 2
1
msysdd: number of threads 3
1
msysvs: number of threads 1
1
mbalvs: number of threads 1
1
mbalvs: number of threads 2
1
mbalvs: number of threads 3
1
energysys: number of threads 1
1
energy_bal: number of threads 1
1
energy_bal: number of threads 2
1
velodd: number of threads 1
1
nexttime: number of threads 1
1
nexttime: number of threads 2
1
infcvs: number of threads 1
1
xyzcoord: number of threads 1
1
cvolume: number of threads 1
1
iajavs: number of threads 1
1
iajavs: number of threads 2
1
iajavs_dp: number of threads 1
1
iajavs_ener: number of threads 1
1
iajavs_ener: number of threads 2
1
matrix_uti: number of threads 1
1
iajart: number of threads 1
1
iajart: number of threads 2
1
initpppm: number of threads 1
1
initppdd: number of threads 1
1
initppvs: number of threads 1
1
initppvs: number of threads 2
1
initppeb: number of threads 1
1
initppeb: number of threads 2
1
initicvs: number of threads 1
1
initsatw: number of threads 1
1
initsatw: number of threads 2
1
initsatw: number of threads 3
1
initicener: number of threads 1
1
initprob: number of threads 1
1
initprob: number of threads 2
1
initicrt: number of threads 1
1
initicdd: number of threads 1
1
restart_r: number of threads 1
1
batreac: number of threads 1
1
batreac: number of threads 2
1